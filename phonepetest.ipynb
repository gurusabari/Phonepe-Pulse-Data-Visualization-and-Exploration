{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "from streamlit_option_menu import option_menu\n",
    "from PIL import Image\n",
    "import requests\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host = \"localhost\",\n",
    "                        user = \"postgres\",\n",
    "                        password = \"changeme\",\n",
    "                        database = \"phonepe_pulse_data\",\n",
    "                        port = \"5432\"\n",
    "                        )\n",
    "cursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_transaction\n",
    "\n",
    "path1 = \"D:/Program Files/Visual Studio/phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "agg_tran_list = os.listdir(path1)\n",
    "\n",
    "columns1 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Transaction_type\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in agg_tran_list:\n",
    "    cur_states = path1+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year+file\n",
    "            data = open(cur_file,\"r\")\n",
    "            \n",
    "            A = json.load(data)\n",
    "            \n",
    "            for i in A[\"data\"][\"transactionData\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                columns1[\"Transaction_type\"].append(name)\n",
    "                columns1[\"Transaction_count\"].append(count)\n",
    "                columns1[\"Transaction_amount\"].append(amount)\n",
    "                columns1[\"States\"].append(state)\n",
    "                columns1[\"Years\"].append(year)\n",
    "                columns1[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "                \n",
    "aggre_transaction = pd.DataFrame(columns1)\n",
    "\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.title()\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated transaction table\n",
    "create_query1 = '''CREATE TABLE if not exists aggregated_transaction (States varchar(50),\n",
    "                                                                      Years int,\n",
    "                                                                      Quarter int,\n",
    "                                                                      Transaction_type varchar(50),\n",
    "                                                                      Transaction_count bigint,\n",
    "                                                                      Transaction_amount bigint\n",
    "                                                                      )'''\n",
    "cursor.execute(create_query1)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in aggre_transaction.iterrows():\n",
    "    insert_query1 = '''INSERT INTO aggregated_transaction (States, Years, Quarter, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                                                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Transaction_type\"],\n",
    "              row[\"Transaction_count\"],\n",
    "              row[\"Transaction_amount\"]\n",
    "              )\n",
    "    cursor.execute(insert_query1,values)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_user\n",
    "\n",
    "path2 = \"D:/Program Files/Visual Studio/phonepe/pulse/data/aggregated/user/country/india/state/\"\n",
    "agg_user_list = os.listdir(path2)\n",
    "\n",
    "columns2 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Brands\":[], \"Transaction_count\":[], \"Percentage\":[]}\n",
    "\n",
    "for state in agg_user_list:\n",
    "    cur_states = path2+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year+file\n",
    "            data = open(cur_file,\"r\")\n",
    "            \n",
    "            B = json.load(data)\n",
    "            \n",
    "            try:\n",
    "                for i in B[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "                    columns2[\"Brands\"].append(brand)\n",
    "                    columns2[\"Transaction_count\"].append(count)\n",
    "                    columns2[\"Percentage\"].append(percentage)\n",
    "                    columns2[\"States\"].append(state)\n",
    "                    columns2[\"Years\"].append(year)\n",
    "                    columns2[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "                    \n",
    "            except:\n",
    "                pass      \n",
    "    \n",
    "aggre_user = pd.DataFrame(columns2)\n",
    "\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.title()\n",
    "aggre_user['States'] = aggre_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated user table\n",
    "create_query2 = '''CREATE TABLE if not exists aggregated_user (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                Brands varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Percentage float)'''\n",
    "cursor.execute(create_query2)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in aggre_user.iterrows():\n",
    "    insert_query2 = '''INSERT INTO aggregated_user (States, Years, Quarter, Brands, Transaction_count, Percentage)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Brands\"],\n",
    "              row[\"Transaction_count\"],\n",
    "              row[\"Percentage\"])\n",
    "    cursor.execute(insert_query2,values)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_transaction\n",
    "\n",
    "path3 = \"D:/Program Files/Visual Studio/phonepe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "map_tran_list = os.listdir(path3)\n",
    "\n",
    "columns3 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"District\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in map_tran_list:\n",
    "    cur_states = path3+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year+file\n",
    "            data = open(cur_file,\"r\")\n",
    "            \n",
    "            C = json.load(data)\n",
    "            \n",
    "            for i in C[\"data\"][\"hoverDataList\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"metric\"][0][\"count\"]\n",
    "                    amount = i[\"metric\"][0][\"amount\"]\n",
    "                    columns3[\"District\"].append(name)\n",
    "                    columns3[\"Transaction_count\"].append(count)\n",
    "                    columns3[\"Transaction_amount\"].append(amount)\n",
    "                    columns3[\"States\"].append(state)\n",
    "                    columns3[\"Years\"].append(year)\n",
    "                    columns3[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "                    \n",
    "map_transaction = pd.DataFrame(columns3)\n",
    "\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.title()\n",
    "map_transaction['States'] = map_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_transaction_table\n",
    "create_query3 = '''CREATE TABLE if not exists map_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                District varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount float)'''\n",
    "cursor.execute(create_query3)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in map_transaction.iterrows():\n",
    "            insert_query3 = '''\n",
    "                INSERT INTO map_Transaction (States, Years, Quarter, District, Transaction_count, Transaction_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "\n",
    "            '''\n",
    "            values = (\n",
    "                row['States'],\n",
    "                row['Years'],\n",
    "                row['Quarter'],\n",
    "                row['District'],\n",
    "                row['Transaction_count'],\n",
    "                row['Transaction_amount']\n",
    "            )\n",
    "            cursor.execute(insert_query3,values)\n",
    "            mydb.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_user\n",
    "\n",
    "path4 = \"D:/Program Files/Visual Studio/phonepe/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_user_list = os.listdir(path4)\n",
    "\n",
    "columns4 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"RegisteredUser\":[], \"AppOpens\":[]}\n",
    "\n",
    "for state in map_user_list:\n",
    "    cur_states = path4+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year+file\n",
    "            data = open(cur_file,\"r\")\n",
    "            \n",
    "            D = json.load(data)\n",
    "            \n",
    "            for i in D[\"data\"][\"hoverData\"].items():\n",
    "                district = i[0]\n",
    "                registereduser = i[1][\"registeredUsers\"]\n",
    "                appopens = i[1][\"appOpens\"]\n",
    "                columns4[\"Districts\"].append(district)\n",
    "                columns4[\"RegisteredUser\"].append(registereduser)\n",
    "                columns4[\"AppOpens\"].append(appopens)\n",
    "                columns4[\"States\"].append(state)\n",
    "                columns4[\"Years\"].append(year)\n",
    "                columns4[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "                \n",
    "map_user = pd.DataFrame(columns4)\n",
    "\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"-\",\" \")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.title()\n",
    "map_user['States'] = map_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_user_table\n",
    "create_query4 = '''CREATE TABLE if not exists map_user (States varchar(50),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Districts varchar(50),\n",
    "                                                        RegisteredUser bigint,\n",
    "                                                        AppOpens bigint)'''\n",
    "cursor.execute(create_query4)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in map_user.iterrows():\n",
    "    insert_query4 = '''INSERT INTO map_user (States, Years, Quarter, Districts, RegisteredUser, AppOpens)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Districts\"],\n",
    "              row[\"RegisteredUser\"],\n",
    "              row[\"AppOpens\"])\n",
    "    cursor.execute(insert_query4,values)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_transaction\n",
    "\n",
    "path5 = \"D:/Program Files/Visual Studio/phonepe/pulse/data/top/transaction/country/india/state/\"\n",
    "top_tran_list = os.listdir(path5)\n",
    "\n",
    "columns5 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_tran_list:\n",
    "    cur_states = path5+state+\"/\"\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in top_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        top_file_list = os.listdir(cur_years)\n",
    "        \n",
    "        for file in top_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            E = json.load(data)\n",
    "\n",
    "            for i in E[\"data\"][\"pincodes\"]:\n",
    "                entityName = i[\"entityName\"]\n",
    "                count = i[\"metric\"][\"count\"]\n",
    "                amount = i[\"metric\"][\"amount\"]\n",
    "                columns5[\"Pincodes\"].append(entityName)\n",
    "                columns5[\"Transaction_count\"].append(count)\n",
    "                columns5[\"Transaction_amount\"].append(amount)\n",
    "                columns5[\"States\"].append(state)\n",
    "                columns5[\"Years\"].append(year)\n",
    "                columns5[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "                \n",
    "top_transaction = pd.DataFrame(columns5)\n",
    "\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.title()\n",
    "top_transaction['States'] = top_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_transaction_table\n",
    "create_query5 = '''CREATE TABLE if not exists top_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                pincodes int,\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "cursor.execute(create_query5)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in top_transaction.iterrows():\n",
    "    insert_query5 = '''INSERT INTO top_transaction (States, Years, Quarter, Pincodes, Transaction_count, Transaction_amount)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Pincodes\"],\n",
    "              row[\"Transaction_count\"],\n",
    "              row[\"Transaction_amount\"])\n",
    "    cursor.execute(insert_query5,values)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user\n",
    "\n",
    "path6 = \"D:/Program Files/Visual Studio/phonepe/pulse/data/top/user/country/india/state/\"\n",
    "top_user_list = os.listdir(path6)\n",
    "\n",
    "columns6 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"RegisteredUser\":[]}\n",
    "\n",
    "for state in top_user_list:\n",
    "    cur_states = path6+state+\"/\"\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        top_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            F = json.load(data)\n",
    "\n",
    "            for i in F[\"data\"][\"pincodes\"]:\n",
    "                name = i[\"name\"]\n",
    "                registeredusers = i[\"registeredUsers\"]\n",
    "                columns6[\"Pincodes\"].append(name)\n",
    "                columns6[\"RegisteredUser\"].append(registereduser)\n",
    "                columns6[\"States\"].append(state)\n",
    "                columns6[\"Years\"].append(year)\n",
    "                columns6[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "                \n",
    "top_user = pd.DataFrame(columns6)\n",
    "\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"-\",\" \")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.title()\n",
    "top_user['States'] = top_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user_table\n",
    "create_query6 = '''CREATE TABLE if not exists top_user (States varchar(50),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Pincodes int,\n",
    "                                                        RegisteredUser bigint\n",
    "                                                        )'''\n",
    "cursor.execute(create_query6)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in top_user.iterrows():\n",
    "    insert_query6 = '''INSERT INTO top_user (States, Years, Quarter, Pincodes, RegisteredUser)\n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Pincodes\"],\n",
    "              row[\"RegisteredUser\"])\n",
    "    cursor.execute(insert_query6,values)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch GeoJSON data\n",
    "url = \"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\"\n",
    "response = requests.get(url)\n",
    "data1 = json.loads(response.content)\n",
    "\n",
    "# Extract state names and sort them in alphabetical order\n",
    "state_names = [feature['properties']['ST_NM'] for feature in data1['features']]\n",
    "state_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating connection with MySQL workbench and retrieve the data from the \"agg_trans\" table as dataframe:\n",
    "mydb = psycopg2.connect(host = \"localhost\",\n",
    "                        user = \"postgres\",\n",
    "                        password = \"changeme\",\n",
    "                        database = \"phonepe_pulse\",\n",
    "                        port = \"5432\"\n",
    "                        )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT states, years, quarter, transaction_type, transaction_count, transaction_amount FROM aggregated_transaction\")\n",
    "data = cursor.fetchall()\n",
    "columns = [\"state\", \"year\", \"quarter\", \"transaction_type\", \"transaction_count\", \"transaction_amount\"]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df\n",
    "\n",
    "#Find unique values in column 'A'\n",
    "pd.DataFrame(df['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame 'df' looks like this\n",
    "# df = pd.DataFrame({'states': [...state_names...]})\n",
    "\n",
    "# Define the conversion function\n",
    "def convert_state_name(state):\n",
    "    return state.replace('-', ' ').title()\n",
    "\n",
    "# Apply the conversion function to the 'states' column in the DataFrame\n",
    "df['state'] = df['state'].apply(lambda x: convert_state_name(x))\n",
    "\n",
    "# Assuming you have already converted and updated the DataFrame 'df'\n",
    "df.to_csv('D:/Program Files/Visual Studio/phonepe/data/india_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the \"india_map\" CSV file into a DataFrame\n",
    "df1 = pd.read_csv('D:/Program Files/Visual Studio/phonepe/data/india_map.csv')\n",
    "df1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Transaction Amount: 34\n",
      "Maximum Transaction Amount: 2393380395297\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "min_transaction_amount = df['transaction_amount'].min()\n",
    "max_transaction_amount = df['transaction_amount'].max()\n",
    "\n",
    "print(\"Minimum Transaction Amount:\", min_transaction_amount)\n",
    "print(\"Maximum Transaction Amount:\", max_transaction_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 00:14:05.538 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\sggur\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geo plot\n",
    "\n",
    "\n",
    "fig_tra = px.choropleth(\n",
    "    df1,\n",
    "    geojson=\"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\",\n",
    "    featureidkey='properties.ST_NM',\n",
    "    locations='state',\n",
    "    color='transaction_amount',\n",
    "    color_continuous_scale='thermal',\n",
    "    range_color=(df1['transaction_amount'].min(), df1['transaction_amount'].max()),  # Set custom range\n",
    "    title='Transaction Analysis'\n",
    ")\n",
    "\n",
    "fig_tra.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig_tra.update_layout(title_font=dict(size=33), title_font_color='#6739b7', height=800)\n",
    "\n",
    "st.plotly_chart(fig_tra, use_container_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "\n",
    "# Read the \"india_map\" CSV file into a DataFrame\n",
    "# Assuming df1 is your DataFrame containing the data\n",
    "df1 = pd.read_csv(r'D:/Program Files/Visual Studio/phonepe/data/india_map.csv')\n",
    "df1.head(4)\n",
    "\n",
    "# Debugging statements\n",
    "print(\"Data Types:\")\n",
    "print(df1.dtypes)\n",
    "\n",
    "print(\"Null Values:\")\n",
    "print(df1.isnull().sum())\n",
    "\n",
    "print(\"Transaction Amount Summary:\")\n",
    "print(df1['transaction_amount'].describe())\n",
    "\n",
    "# Calculate the range of transaction_amount for setting zmin and zmax\n",
    "zmin = df1['transaction_amount'].min()\n",
    "zmax = df1['transaction_amount'].max()\n",
    "\n",
    "fig_tra = px.choropleth(\n",
    "    df1,\n",
    "    geojson=\"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\",\n",
    "    featureidkey='properties.ST_NM',\n",
    "    locations='state',\n",
    "    color='transaction_amount',\n",
    "    color_continuous_scale='Viridis',  # Change the color scale\n",
    "    range_color=(zmin, zmax),  # Set custom range\n",
    "    title='Transaction Analysis'\n",
    ")\n",
    "\n",
    "fig_tra.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig_tra.update_layout(title_font=dict(size=33), title_font_color='#6739b7', height=800)\n",
    "\n",
    "st.plotly_chart(fig_tra, use_container_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data query for map_trans :\n",
    "# Creating connection with postgressql and retrieve the data from the \"agg_trans\" table as dataframe:\n",
    "mydb = psycopg2.connect(host = \"localhost\",\n",
    "                        user = \"postgres\",\n",
    "                        password = \"changeme\",\n",
    "                        database = \"phonepe_pulse\",\n",
    "                        port = \"5432\"\n",
    "                        )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT states, years, quarter, District, transaction_count, transaction_Amount FROM map_transaction\")\n",
    "data = cursor.fetchall()\n",
    "columns = [\"state\", \"year\", \"quarter\", \"District\", \"Count\", \"Amount\"]\n",
    "df3 = pd.DataFrame(data, columns=columns)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download to local drive as csv file ;\n",
    "df3.to_csv('D:/Program Files/Visual Studio/phonepe/data/histogram_district.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for voline plot :\n",
    "cursor.execute(\"SELECT States, Years, Quarter, Districts, Registereduser, Appopens FROM map_user\")\n",
    "data = cursor.fetchall()\n",
    "columns = [\"State\", \"Year\", \"Quarter\", \"District\", \"RegisteredUser\", \"AppOpens\"]\n",
    "df4 = pd.DataFrame(data, columns=columns)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download to local drive as csv file ;\n",
    "df4.to_csv('D:/Program Files/Visual Studio/phonepe/data/violin_plot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame 'df' looks like this\n",
    "# df = pd.DataFrame({'states': [...state_names...]})\n",
    "\n",
    "# Define the conversion function\n",
    "def convert_state_name(state):\n",
    "    return state.replace('-', ' ').title()\n",
    "\n",
    "# Apply the conversion function to the 'states' column in the DataFrame\n",
    "df4['State'] = df4['State'].apply(lambda x: convert_state_name(x))\n",
    "\n",
    "# Assuming you have already converted and updated the DataFrame 'df'\n",
    "df4.to_csv('D:/Program Files/Visual Studio/phonepe/data/state_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the \"state_map\" CSV file into a DataFrame:\n",
    "df4 = pd.read_csv('D:/Program Files/Visual Studio/phonepe/data/state_map.csv')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = mydb.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT states, years, quarter, transaction_type, transaction_count, transaction_amount FROM aggregated_transaction\")\n",
    "data = cursor.fetchall()\n",
    "columns = [\"state\", \"year\", \"quarter\", \"transaction_type\", \"transaction_count\", \"transaction_amount\"]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transaction_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data query for map_trans :\n",
    "# Creating connection with postgressql and retrieve the data from the \"aggregated_user\" table as dataframe:\n",
    "mydb = psycopg2.connect(host = \"localhost\",\n",
    "                        user = \"postgres\",\n",
    "                        password = \"changeme\",\n",
    "                        database = \"phonepe_pulse\",\n",
    "                        port = \"5432\"\n",
    "                        )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT states, years, quarter, Brands, transaction_count, percentage FROM aggregated_user\")\n",
    "data = cursor.fetchall()\n",
    "columns = [\"state\", \"year\", \"quarter\", \"Brands\", \"Count\", \"Percentage\"]\n",
    "df5 = pd.DataFrame(data, columns=columns)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download to local drive as csv file ;\n",
    "df5.to_csv('D:/Program Files/Visual Studio/New folder/data/bar_chart.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
